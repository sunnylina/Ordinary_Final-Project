{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawring_en_to_ko_1.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tqdm"
      ],
      "metadata": {
        "id": "dhZB0W9MZMs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnQLDc77UDAf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests                        # HTTP 요청을 보내는 모듈\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm                 # 진행률 프로세스 바\n",
        "import time\n",
        "\n",
        "def get_sub(word):\n",
        "    url = f'https://dict.naver.com/search.dict?dicQuery={word}&query={word}&target=dic&ie=utf8&query_utf=&isOnlyViewEE='\n",
        "    r = requests.get(url)                         # 서버에 요청을 보내는 것 200으로 응답하면 잘 처리 되었다는 의미\n",
        "    html = r.text                                 #  r.text의 경우엔 HTTP Request를 보낸 URL에서 readable한 내용을 가져올 때 사용\n",
        "    soup = BeautifulSoup(html, 'html.parser')     # 수프를 이용해서 원하는 태그를 선택할 수 있음\n",
        "\n",
        "    try:\n",
        "        sent = soup.find('dd').text           # 'p'의 구역에 해당하는 글을 텍스트로 가져온다.\n",
        "    except:\n",
        "        return None\n",
        "    replace = replace_all(sent, replace_list)\n",
        "    final = replace.split('[명사]')\n",
        "    # final = replace.split('[명사]')[1].split('1.')[1].split('.')[0]\n",
        "    return final\n",
        "\n",
        "def get_verb(word, mode=None):\n",
        "    url = f'https://dict.naver.com/search.dict?dicQuery={word}&query={word}&target=dic&ie=utf8&query_utf=&isOnlyViewEE='\n",
        "    r = requests.get(url)\n",
        "    html = r.text\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    try:\n",
        "        sent = soup.find('dd').text\n",
        "    except:\n",
        "        return None\n",
        "    replace = replace_all(sent, replace_list)\n",
        "    final = replace.split('[형용사]')\n",
        "    # 형용사가 존재하면 길이가 2 \n",
        "    if not len(final) ==2:\n",
        "        print(final)\n",
        "        final = final[0].split('[동사]')\n",
        "    # final = replace.split('[명사]')[1].split('1.')[1].split('.')[0]\n",
        "    return final\n",
        "\n",
        "def replace_all(text, remove_list):\n",
        "    for i, j in remove_list:\n",
        "        text = text.replace(i, j)\n",
        "    return text\n",
        "replace_list = [('\\t',''), ('\\r',''),('\\t',''), ('\\n','')]\n",
        "# \\t : 문자열 사이에 탭 간격을 줄 때 사용, \\r : 캐리지 리턴(줄 바꿈 문자, 현재 커서를 가장 앞으로 이동), \\n : 문자열 안에서 줄을 바꿀때 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# noun first\n",
        "base_path = '/content/'\n",
        "path_lists = ['VB']\n",
        "# /content/drive/NNG.csv\n",
        "import os, sys\n",
        "for path in path_lists:\n",
        "    name = base_path+path + '.csv'\n",
        "    verb = pd.read_csv(name, encoding='utf-8')\n",
        "\n",
        "    data_dict = {'word':[], 'type':[],'v1':[]}\n",
        "    for w_idx in tqdm(range(len(verb[path]))):\n",
        "        # print(nouns.NNG[w_idx])\n",
        "        out = get_verb(verb[path][w_idx])\n",
        "        data_dict['word'].append(verb[path][w_idx])\n",
        "        data_dict['type'].append(path)\n",
        "        if out is None:\n",
        "            out = ['NA']\n",
        "            print(w_idx, verb[path][w_idx], out[0])\n",
        "        try:\n",
        "            data_dict['v1'].append(out[1])\n",
        "        except:\n",
        "            data_dict['v1'].append('Not verb')\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    df.to_csv(f'./crawling_{path}.csv')"
      ],
      "metadata": {
        "id": "-GmxIQDmW9lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noun first\n",
        "base_path = '/content/'\n",
        "path_lists = ['VBN']\n",
        "# /content/drive/NNG.csv\n",
        "import os, sys\n",
        "for path in path_lists:\n",
        "    name = base_path+path + '.csv'\n",
        "    verb = pd.read_csv(name, encoding='utf-8')\n",
        "\n",
        "    data_dict = {'word':[], 'type':[],'v1':[]}\n",
        "    for w_idx in tqdm(range(len(verb[path]))):\n",
        "        # print(nouns.NNG[w_idx])\n",
        "        out = get_verb(verb[path][w_idx])\n",
        "        data_dict['word'].append(verb[path][w_idx])\n",
        "        data_dict['type'].append(path)\n",
        "        if out is None:\n",
        "            out = ['NA']\n",
        "            print(w_idx, verb[path][w_idx], out[0])\n",
        "        try:\n",
        "            data_dict['v1'].append(out[1])\n",
        "        except:\n",
        "            data_dict['v1'].append('Not verb')\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    df.to_csv(f'./crawling_{path}.csv')"
      ],
      "metadata": {
        "id": "xTFDHmD7Uaog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Xi-V52mZnXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}