{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f25k_3M_NBuH"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git\n",
        "!pip install konlpy\n",
        "!pip install hangul_utils\n",
        "!pip install git+https://github.com/boostcampaitech3/final-project-level3-nlp-03/eng_to_kor.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import csv\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from hanspell import spell_checker\n",
        "from konlpy.tag import Okt\n",
        "from hangul_utils import join_jamos, split_syllables\n",
        "\n",
        "# from eng_to_kor import eng_to_kor_func"
      ],
      "metadata": {
        "id": "TRHBuwhWNDUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_synonyms(word):\n",
        "    url = f\"https://www.thesaurus.com/browse/{word}\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        html = response.text\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        n_of_word = 2\n",
        "        words = []\n",
        "        for i in range(1, n_of_word + 1):\n",
        "            word = soup.select(\n",
        "             #   f\"#antonyms > div.css-ixatld.e15rdun50 > ul > li:nth-of-type({i}) > a\"    #nth 뒷부분 바꿔줬음\n",
        "            \n",
        "                f\"#meanings > div.css-ixatld.e15rdun50 > ul > li:nth-of-type({i}) > a\"     # 유의어\n",
        "            )\n",
        "            if str(word) == \"[]\":\n",
        "                pass\n",
        "            else:\n",
        "                word = str(word).split(\"<!-- -->\")\n",
        "                word = word[0].split('\">')[1]\n",
        "            words.append(word)\n",
        "        return words\n",
        "    else:\n",
        "        words = []\n",
        "        return words\n",
        "    words.to_csv(f\"./synonyms_{csv_type}.csv\")"
      ],
      "metadata": {
        "id": "AwY-XLXlNDRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_synonyms(\"abolish\")"
      ],
      "metadata": {
        "id": "KM13wvJpPXdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataframe(csv_type, is_da):\n",
        "    df_name = f\"WAI-{csv_type}-origin\"\n",
        "    csv_name = f\"WAI-para_{csv_type}.csv\"\n",
        "\n",
        "    word_df = pd.DataFrame(\n",
        "        columns=(\"original\", \"synonyms\")\n",
        "    )\n",
        "    word_list = pd.read_csv(csv_name)\n",
        "    for word in tqdm(word_list[csv_type]):\n",
        "        # word = spell_correct(word)\n",
        "        origin = word\n",
        "        if not is_da:\n",
        "            origin = word[:-1]\n",
        "        # translated_original = translate(origin)\n",
        "        translated_synonyms = find_synonyms(word)\n",
        "        synonyms = []\n",
        "\n",
        "        for word in translated_synonyms:\n",
        "            if word:\n",
        "                synonyms.append(word)\n",
        "                # synonyms.append(eng_to_kor_func(word))\n",
        "            else:\n",
        "                synonyms.append(\"\")\n",
        "        new_data = {\n",
        "            \"original\": origin,\n",
        "            \"synonyms\": synonyms,\n",
        "        }\n",
        "        new_df = pd.DataFrame(new_data)\n",
        "        word_df = pd.concat([word_df, new_df])\n",
        "    word_df.to_csv(f\"./{df_name}.csv\")"
      ],
      "metadata": {
        "id": "7-PsnQFxNDOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    #데이터셋이 동일한 폴더 안에 있어야 하는 코드로, 경로가 바뀐다면 조정이 필요합니다.\n",
        "    origin = make_dataframe(\"VB\", 1)"
      ],
      "metadata": {
        "id": "Z7BjDUtkVd33",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Ex1FMWyTVhZT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BvecD6zNDGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ii-pQ3HNC_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}